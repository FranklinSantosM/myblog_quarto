---
title: "Análisis de Varianza y Prueba de Promedios en R"
description: |
  La figura de prueba de promedios de TukeyHSD es una buena opción, ya que incluye p-valor del ANVA y de la comparación de medias entre tratamientos.
categories:
  - ANOVA
  - Post hoc
  - Inferencial Statistic
author:
  - name: Franklin Santos
    url: https://franklinsantos.com
    affiliation: AgriTech Bolivia
    orcid: 0000-0002-7509-2910
date: "2020-11-15"
image: "featured.png"
---

```{=html}
<style>
body {
text-align: justify}
</style>
```

## Introducción

El análisis de varianza es una prueba estadística para determinar si dos o más medias poblacionales son diferentes entre si. En otras palabras, se usa para comparar dos o más grupos para ver si son significativamente diferentes.

En el resto del post lo comentaremos desde un punto de vista más práctico y en particular abordaremos los siguientes puntos:

-   el objetivo del análisis de varianza y cuándo debe usarse
-   cómo realizar el ANVA en R
-   cómo interpretar los resultados del ANVA
-   comprender la noción de prueba de promedios e interpretar los resultados
-   cómo visualizar los resultados de ANVA y pruebas de promedio

## Datos

El dato que se utilizará es `iris`, que se encuentra en la base de datos de R. Estos datos como tratamientos tienen tres especies (`setosa`, `versicolor` y `virginica`) y cuatro variables (`Sepal.Length`, `Sepal.Width`, `Petal.Length` y `Petal.Width`) cuantitativas

```{r, message=FALSE, warning=FALSE}
#paquetes R a utilizar
library(tidyverse)
library(easyanova)
library(car)
library(lattice)
library(multcomp)
library(ggpubr)
library(rstatix)
```

La librería de `easyanova` es un paquete para realizar análisis de experimentos agrícolas y animales. Las funciones de esta librería son fáciles de usar. Realiza análisis en varios diseños, con datos balanceados y no balanceados.

Salida de datos a utilizar:

```{r}
#datos
tibble(iris)
```

```{r}
#| warning: false
#inspección de datos
p <- ggplot(iris) +
  aes(x = Species, y = Sepal.Width, color = Species) +
  geom_jitter() +
  theme(legend.position = "none")

library(plotly)
fig <- ggplotly(p)

fig
```

## Objetivo del ANVA

Como se mencionó en la introducción, el ANVA se usa para comparar grupos (en la práctica, 3 o más grupos). De manera más general, se utiliza para:

-   estudiar si las mediciones son similares en diferentes modalidades (también llamadas niveles o tratamientos en el contexto de ANVA) de una variable categórica
-   comparar el impacto de los diferentes niveles de una variable categórica sobre una variable cuantitativa
-   explicar una variable cuantitativa basada en una variable cualitativa

## Supuestos subyacentes de ANVA

Como ocurre con muchas pruebas estadísticas, hay algunas suposiciones que deben cumplirse para poder interpretar los resultados. Cuando no se cumplen uno o varios supuestos, aunque técnicamente es posible realizar estas pruebas, sería incorrecto interpretar los resultados y confiar en las conclusiones.

### 1. Tipo de variable

Las variables dependientes `Sepal.Length`, `Sepal.Width`, `Petal.Length` y `Petal.Width` es una variable **cuantitativa** y la variable independiente `Species` es **cualitativa** (con 3 niveles correspondientes a las 3 especies). Así que tenemos una combinación de los dos tipos de variables y se cumple este supuesto.

### 2. Independencia

Se asume la independencia de las observaciones ya que los datos se han recopilado de una parte de la población seleccionada al azar y las mediciones dentro y entre las 3 muestras no están relacionadas.

El supuesto de independencia se verifica con mayor frecuencia con base en el diseño del experimento y en el buen control de las condiciones experimentales, como es el caso aquí. Sin embargo, si realmente desea probarlo de manera más formal, puede probarlo mediante una prueba estadística: la prueba de Durbin-Watson (en R: `durbinWatsonTest(res_lm)` donde `res_lm` es un modelo lineal). La hipótesis nula de esta prueba especifica un coeficiente de autocorrelación = 0, mientras que la hipótesis alternativa especifica un coeficiente de autocorrelación ≠ 0.

### 3. Normalidad

Recuerde que la **normalidad** de los residuos se puede probar visualmente mediante un histograma y un gráfico QQ, y/o formalmente mediante una prueba de normalidad (prueba de Shapiro-Wilk, por ejemplo).

Antes de verificar el supuesto de normalidad, primero debemos calcular el ANVA. Luego guardamos los resultados en `res_aov`:

```{r, echo=TRUE}
res_aov <- aov(Sepal.Width ~ Species,
  data = iris
)
```

Ahora podemos comprobar la normalidad visualmente:

```{r, echo=TRUE}
par(mfrow = c(1, 2)) # combine plots

# histogram
hist(res_aov$residuals)

# QQ-plot
qqPlot(res_aov$residuals,
  id = FALSE # id = FALSE to remove point identification
)
```

A partir del histograma y el gráfico QQ anteriores, ya podemos ver que el supuesto de normalidad parece cumplirse. De hecho, el histograma forma aproximadamente una curva de campana, lo que indica que los residuos siguen una distribución normal. Además, los puntos en las gráficas QQ siguen aproximadamente la línea recta y la mayoría de ellos están dentro de las bandas de confianza, lo que también indica que los residuos siguen aproximadamente una distribución normal.

Algunos investigadores se detienen aquí y asumen que se cumple la normalidad, mientras que otros también prueban la suposición a través de una prueba estadística formal. Es su elección probarlo *(i)* solo visualmente, *(ii)* solo a través de una prueba de normalidad, o *(iii)* tanto visualmente como a través de una prueba de normalidad. Sin embargo, tenga en cuenta los dos puntos siguientes:

> 1.  ANVA es bastante robusto a pequeñas desviaciones de la normalidad. Esto significa que no es un problema (desde la perspectiva de la interpretación de los resultados de ANVA) si un pequeño número de puntos se desvía ligeramente de la normalidad,
> 2.  Las pruebas de normalidad son a veces bastante conservadoras, lo que significa que la hipótesis nula de normalidad puede rechazarse debido a una desviación limitada de la normalidad. Este es especialmente el caso con muestras grandes, ya que la potencia de la prueba aumenta con el tamaño de la muestra.

En la práctica, se tiende a preferir el (i) enfoque visual solamente, pero nuevamente, esto es una cuestión de elección personal y también depende del contexto del análisis. Tambien, puede utilizar la prueba de Shapiro-Wilk o la prueba de Kolmogorov-Smirnov, entre otras.

### 4. Igualdad de varianzas - homogeneidad

Suponiendo que los residuos siguen una distribución normal, ahora es el momento de comprobar si las varianzas son iguales entre especies o no. El resultado tendrá un impacto en si usamos el ANVA o la prueba de Welch.

Esto se puede verificar nuevamente visualmente, a través de una gráfica de caja o gráfica de puntos, o más formalmente a través de una prueba estadística (la prueba de Levene, entre otras).

Visualmente tenemos:

```{r, echo=TRUE}
# Boxplot
boxplot(Sepal.Width ~ Species,
  data = iris
)
```

```{r, echo=TRUE}
# Dotplot

dotplot(Sepal.Width ~ Species,
  data = iris
)
```

Tanto la gráfica de boxplot como la gráfica de puntos muestran una variación similar para las diferentes especies. En el boxplot, esto se puede ver por el hecho de que las cajas y los bigotes tienen un tamaño comparable para todas las especies. Hay un par de valores atípicos como lo muestran los puntos fuera de los bigotes, pero esto no cambia el hecho de que la dispersión es más o menos la misma entre las diferentes especies.

En la gráfica de puntos, esto se puede ver por el hecho de que los puntos para las 3 especies tienen más o menos el mismo rango, un signo de la dispersión y, por lo tanto, la varianza es similar.

Al igual que el supuesto de normalidad, si cree que el enfoque visual no es suficiente, puede probar formalmente la igualdad de las varianzas con una prueba de *Levene* o de *Bartlett*. Observe que la prueba de Levene es menos sensible a las desviaciones de la distribución normal que la prueba de Bartlett.

Las hipótesis nula y alternativa para ambas pruebas son:

-   H0: las variaciones son iguales
-   H1: al menos una varianza es diferente

En R, la prueba de Levene se puede realizar gracias a la función `leveneTest()` del paquete `{car}`:

```{r, echo=TRUE}
# Levene's test

leveneTest(Sepal.Width ~ Species,
  data = iris
)
```

Siendo el *p*-valor mayor que el nivel de significancia de 0.05, no rechazamos la hipótesis nula, por lo que no podemos rechazar la hipótesis de que las varianzas son iguales entre especies (*p*-valor = 0.556).

Este resultado también está en línea con el enfoque visual, por lo que la homogeneidad de las variaciones se cumple tanto visual como formalmente.

## Análisis de varianza en R

El ANVA puede ayudarnos a hacer inferencias sobre la población dada la muestra en cuestión y ayudarnos a responder la pregunta de investigación "¿Existe diferencia en ancho de sépalo para las 3 especies?".

El ANVA en R se puede realizar de varias formas, de las cuales tres se presentan a continuación:

a). Con la función `oneway.test()`:

```{r}
# primer metodo:
oneway.test(Sepal.Width ~ Species,
  data = iris,
  var.equal = TRUE # asumiendo varianzas iguales
)
```

b). Con las funciones de `summary()` y `aov()`:

```{r}
# 2nd method:
res_aov <- aov(Sepal.Width ~ Species,
  data = iris
)

summary(res_aov)
```

Como puede ver en los dos resultados anteriores, la estadística de prueba (F = en el primer método y el valor F en el segundo) y el *p*-valor (*p*-valor en el primer método y Pr (\> F) en el segundo) son exactamente iguales para ambos métodos, lo que significa que en caso de variaciones iguales, los resultados y las conclusiones no cambiarán.

La ventaja del primer método es que es fácil cambiar del ANVA (utilizado cuando las variaciones son iguales) a la prueba de Welch (utilizado cuando las variaciones son desiguales). Esto se puede hacer reemplazando `nvar.equal = TRUE` por `var.equal = FALSE`, como se presenta a continuación:

```{r}
oneway.test(Sepal.Width ~ Species,
  data = iris,
  var.equal = FALSE # asumiendo variaciones desiguales
)
```

Sin embargo, la ventaja del segundo método es que:

-   Se imprime la tabla ANVA completa (con grados de libertad, cuadrados medios, etc.), lo que puede ser de interés en algunos casos (teóricos).
-   los resultados del ANVA (`res_aov`) se pueden guardar para su uso posterior (especialmente útil para pruebas de promedio)

### Interpretaciones de los resultados del ANVA

Dado que el p-valor es menor que 0.05, rechazamos la hipótesis nula, por lo que rechazamos la hipótesis de que todas las medias son iguales. Por tanto, podemos concluir que al menos una especie es diferente a las otras en términos del ancho de sépalo (*p*-valor \<2.2e-16).

### ¿Que sigue?

Si **no se rechaza la hipótesis nula** (*p*-valor ≥ 0,05), significa que no rechazamos la hipótesis de que todos los grupos son iguales. El ANVA más o menos se detiene aquí. Por supuesto, se pueden realizar otros tipos de análisis, pero, dados los datos disponibles, no pudimos probar que al menos un grupo fuera diferente, por lo que generalmente no avanzamos más con el ANVA.

Por el contrario, *si y solo si* se **rechaza la hipótesis nula** (como es nuestro caso ya que el *p*-valor \< 0.05), probamos que al menos un grupo es diferente. Podemos decidir detenernos aquí si solo estamos interesados en probar si todas las especies son iguales en términos de ancho de sépalo.

Pero la mayoría de las veces, cuando demostramos gracias a un ANVA que al menos un grupo es diferente, también nos interesa saber cuál es diferente. Para probar esto, necesitamos usar otros tipos de prueba, denominados pruebas de promedio o pruebas de comparación múltiple por pares. Esta familia de pruebas estadísticas es el tema de las siguientes secciones.

## Pruebas de promedio en R y su interpretación

Las pruebas de promedio son una familia de pruebas estadísticas, por lo que hay varias. Las más utilizadas son las pruebas **Tukey HSD** y **Dunnett**:

-   Tukey HSD se utiliza para comparar **todos los grupos** entre sí (por lo que todas las posibles comparaciones de 2 grupos).
-   Dunnett se utiliza para hacer comparaciones con un **grupo de referencia**. Por ejemplo, considere 2 grupos de tratamiento y un grupo de control. Si solo desea comparar los 2 grupos de tratamiento con respecto al grupo de control y no desea comparar los 2 grupos de tratamiento entre sí, se prefiere la prueba de Dunnett.

Ambas pruebas se presentan en las siguientes secciones.

### Prueba de Tukey HSD

En nuestro caso, dado que no existe una especie de "referencia" y nos interesa comparar todas las especies, vamos a utilizar la prueba de Tukey HSD.

En R, la prueba de Tukey HSD se realiza de la siguiente manera. Aquí es donde el *segundo método* para realizar el ANVA resulta útil porque los resultados (`res_aov`) se reutilizan para la prueba de promedios:

```{r}

# Prueba de Tukey HSD:
post_test <- glht(res_aov,
  linfct = mcp(Species = "Tukey")
)
summary(post_test)
```

En el resultado de la prueba Tukey HSD, nos interesa la tabla que se muestra después de las `Hipótesis lineales`: más precisamente, en la primera y última columna de la tabla. La primera columna muestra las comparaciones que se han realizado; la última columna (`Pr(>|t|)`) muestra los *p*-valores ajustados para cada comparación (con la hipótesis nula siendo los dos grupos iguales y la hipótesis alternativa siendo los dos grupos diferentes).

Son estos *p*-valores ajustados los que se utilizan para probar si dos grupos son significativamente diferentes o no. En nuestro ejemplo, probamos:

1.  versicolor vs setosa (línea `versicolor - setosa == 0`)
2.  virginica vs setosa (línea `virginica - setosa == 0`)
3.  virginica vs versicolor (línea `virginica - versicolor == 0`)

Los tres p-valores son menores que 0.05, por lo que rechazamos la hipótesis nula para todas las comparaciones, lo que significa que todas las especies son **significativamente diferentes** en términos de ancho de sépalo.

Tenga en cuenta que la prueba Tukey HSD también se puede realizar en R con la función `TukeyHSD()`:

```{r}
TukeyHSD(res_aov)
```

Con este código, es la columna `p adj` (también la última columna) la que interesa. Tenga en cuenta que las conclusiones son las mismas que las anteriores: todas las especies son significativamente diferentes en términos de ancho de sépalo.

## Visualización de ANVA y pruebas de promedio

Para realizar de forma más fácil un análisis de varianza, se puede usar la librería `easyanova` para analizar diferentes diseños experimentales.

### Análisis de varianza con `easyanova`

Para proceder con ANVA los datos de `iris` se selecciona y ordena para dar uso con el paquete `easyanova`.

```{r}
fsdata <- iris %>%
  dplyr::select(Species, Sepal.Width)
tibble(fsdata)
```

```{r}
# Análisis de varianza para DCA

r1 <- ea1(data = fsdata, # Base de datos
          design = 1, # Diseño experimental: 1=DCA, 2=DBCA, etc.
          alpha = 0.05) # Probabilidad estadística
r1
```

En la salida se puede observar el resultado de `análisis de varianza`, `prueba de promedios` y `comparación múltiple de medias`. Estas salidas son muy fáciles de obtener y poder interpretar las mismas. Asimismo, se puede verificar la `normalidad` y `coeficiente de variación` de los datos.

### Visualización de la prueba de promedios

Si está interesado en incluir resultados de ANVA y pruebas de promedio directamente en los boxplot, aquí hay un fragmento de código que puede ser de su interés:

```{r}
#paquete para p-valor en la visualización de prueba de promedios

dat <- iris
# Editar desde aquí
x <- which(names(dat) == "Species") #variable de agrupación
y <- which(names(dat) == "Sepal.Width") 
#variables para la prueba de promedios
          #| names(dat) == "Sepal.Length"
          #| names(dat) == "Petal.Length"
          #| names(dat) == "Petal.Width")
method1 <- "anova" # Una de "anova" o "kruskal.test"
method2 <- "t.test" # Una de "wilcox.test" o "t.test"
my_comparisons <- list(c("setosa", "versicolor"), 
                       c("setosa", "virginica"), 
                       c("versicolor", "virginica")) 
# comparaciones para pruebas de promedio
# Editar hasta aquí

# Edit at your own risk
for (i in y) {
  for (j in x) {
    p <- ggboxplot(dat,
      x = colnames(dat[j]), y = colnames(dat[i]),
      color = colnames(dat[j]),
      legend = "none",
      palette = "npg",
      add = "jitter"
    )
    print(
      p + stat_compare_means(aes(
        label = paste0(..method.., ", p-value = ", ..p.format..)),
        method = method1, label.y = max(dat[, i], na.rm = TRUE)
      )
      + stat_compare_means(comparisons = my_comparisons, 
                           method = method2, label = "p.format") 
      # remove if p-value of ANOVA or Kruskal-Wallis test >= alpha
    )
  }
}
```

Otra opción de gráfica para observar la significancia entre las medias de cada par de especies.

```{r}
# pairwise comparisons

pwc <- fsdata %>%
  pairwise_t_test(
    Sepal.Width ~ Species, pool.sd = FALSE,
    p.adjust.method = "none"
    )

# Visualization: box plots with p-values
pwc <- pwc %>% add_xy_position(x = "Species")
ggboxplot(fsdata, x = "Species", y = "Sepal.Width",
          color = "Species", 
          legend = "none", 
          add = "jitter") +
  stat_pvalue_manual(pwc, hide.ns = TRUE) 
```

## Conclusión

La figura de prueba de promedios es muy buena opción para incluir en la sección de resultados de los reportes de investigación. La figura incluye el resultado de p-valor del análisis de varianza, además, p-valor para la comparación de medias entre especies o tratamientos de la investigación.

## Referencias

1.  R bloggers 2020. [ANOVA in R](https://www.r-bloggers.com/2020/10/anova-in-r/)
2.  Soetewey A. 2020. [How to do a t-test or ANOVA for more than one variable at once in R](https://towardsdatascience.com/how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-6defaa712e5)
