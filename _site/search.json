[
  {
    "objectID": "posts/tidyexam/index.html",
    "href": "posts/tidyexam/index.html",
    "title": "Ordenar datos con el paquete Tidyverse",
    "section": "",
    "text": "La ordenación de datos es una de las tareas mas importantes despues de concluir la investigación. En las ciencias agrícolas, generalmente la investigación concluye con la evaluación de la cosecha del cultivo. Generalmente nuestros datos pueden estar organizados en un libro de campo; sin embargo, en otras áreas no es así.\nEn este blog replicaré un ejemplo de ordenación de datos con el paquete Tidyverse del libro R4DS. El dataset datos::oms contiene datos de tuberculosis (TB) detallados por año, país, edad, sexo y método de diagnóstico. Los datos provienen del Informe de Tuberculosis de la Organización Mundial de la Salud 2014, disponible en http://www.who.int/tb/country/data/download/en/."
  },
  {
    "objectID": "posts/tidyexam/index.html#procedimiento-de-ordenación",
    "href": "posts/tidyexam/index.html#procedimiento-de-ordenación",
    "title": "Ordenar datos con el paquete Tidyverse",
    "section": "Procedimiento de ordenación",
    "text": "Procedimiento de ordenación\n\nCargar el paquete tidyverse\nEl primer paso es instalar el paquete tidyverse del CRAN de R. Posterior a esto es cargar el paquete en nuestra consola de R.\n\nlibrary(tidyverse)\n#En el paquete datos se encuentra la base de datos para este ejemplo\nlibrary(datos)\n\nA continuación observación el estado de los datos de oms.\n\nhead(oms)\n\n# A tibble: 6 × 60\n  pais       iso2  iso3   anio nuevos_…¹ nuevo…² nuevo…³ nuevo…⁴ nuevo…⁵ nuevo…⁶\n  <chr>      <chr> <chr> <int>     <int>   <int>   <int>   <int>   <int>   <int>\n1 Afganistán AF    AFG    1980        NA      NA      NA      NA      NA      NA\n2 Afganistán AF    AFG    1981        NA      NA      NA      NA      NA      NA\n3 Afganistán AF    AFG    1982        NA      NA      NA      NA      NA      NA\n4 Afganistán AF    AFG    1983        NA      NA      NA      NA      NA      NA\n5 Afganistán AF    AFG    1984        NA      NA      NA      NA      NA      NA\n6 Afganistán AF    AFG    1985        NA      NA      NA      NA      NA      NA\n# … with 50 more variables: nuevos_fpp_h65 <int>, nuevos_fpp_m014 <int>,\n#   nuevos_fpp_m1524 <int>, nuevos_fpp_m2534 <int>, nuevos_fpp_m3544 <int>,\n#   nuevos_fpp_m4554 <int>, nuevos_fpp_m5564 <int>, nuevos_fpp_m65 <int>,\n#   nuevos_fpn_h014 <int>, nuevos_fpn_h1524 <int>, nuevos_fpn_h2534 <int>,\n#   nuevos_fpn_h3544 <int>, nuevos_fpn_h4554 <int>, nuevos_fpn_h5564 <int>,\n#   nuevos_fpn_h65 <int>, nuevos_fpn_m014 <int>, nuevos_fpn_m1524 <int>,\n#   nuevos_fpn_m2534 <int>, nuevos_fpn_m3544 <int>, nuevos_fpn_m4554 <int>, …\n\n\nEn la salida se observa un ejemplo muy típico de una base de datos de la vida real. Contiene columnas redundantes, códigos extraños de variables y muchos valores faltantes. Practicamente, la base de datos oms está desordenado, por tanto, se necesita ordenarlo de manera sencilla con tidyverse.\n\n\nPasos de ordenación\nNecesitamos agrupar todas las columnas desde nuevos_fpp_h014 hasta recaidas_m65. No sabemos aún qué representa esto, por lo que le daremos el nombre genérico de \"clave\". Sabemos que las celdas representan la cuenta de casos, por lo que usaremos la variable casos.\nExisten múltiples valores faltantes en la representación actual, por lo que de momento usaremos na.rm para centrarnos en los valores que están presentes.\n\noms1 <- oms %>%\n  pivot_longer(\n    cols = nuevos_fpp_h014:nuevosrecaida_m65, \n    names_to = \"clave\", \n    values_to = \"casos\", \n    values_drop_na = TRUE\n  )\noms1\n\n# A tibble: 76,046 × 6\n   pais       iso2  iso3   anio clave            casos\n   <chr>      <chr> <chr> <int> <chr>            <int>\n 1 Afganistán AF    AFG    1997 nuevos_fpp_h014      0\n 2 Afganistán AF    AFG    1997 nuevos_fpp_h1524    10\n 3 Afganistán AF    AFG    1997 nuevos_fpp_h2534     6\n 4 Afganistán AF    AFG    1997 nuevos_fpp_h3544     3\n 5 Afganistán AF    AFG    1997 nuevos_fpp_h4554     5\n 6 Afganistán AF    AFG    1997 nuevos_fpp_h5564     2\n 7 Afganistán AF    AFG    1997 nuevos_fpp_h65       0\n 8 Afganistán AF    AFG    1997 nuevos_fpp_m014      5\n 9 Afganistán AF    AFG    1997 nuevos_fpp_m1524    38\n10 Afganistán AF    AFG    1997 nuevos_fpp_m2534    36\n# … with 76,036 more rows\n\n\nPara visualizar el conteo de valores en la nueva columna clave:\n\noms1 %>%\n  count(clave)\n\n# A tibble: 56 × 2\n   clave               n\n   <chr>           <int>\n 1 nuevos_ep_h014   1038\n 2 nuevos_ep_h1524  1026\n 3 nuevos_ep_h2534  1020\n 4 nuevos_ep_h3544  1024\n 5 nuevos_ep_h4554  1020\n 6 nuevos_ep_h5564  1015\n 7 nuevos_ep_h65    1018\n 8 nuevos_ep_m014   1032\n 9 nuevos_ep_m1524  1021\n10 nuevos_ep_m2534  1021\n# … with 46 more rows\n\n\nPara entender el significado de cada variable, se dispone de un diccionario de datos a mano. Este dice lo siguiente:\n\nLo que aparece antes del primer _ en las columnas indica si la columna contiene casos nuevos o antiguos de tuberculosis. En este dataset, cada columna contiene nuevos casos.\nLo que aparece luego de indicar si se refiere casos nuevos o antiguos es el tipo de tuberculosis:\n\n\nrecaida se refiere a casos reincidentes\nep se refiere a tuberculosis extra pulmonar\nfpn se refiere a casos de tuberculosis pulmonar que no se pueden detectar mediante examen de frotis pulmonar (frotis pulmonar negativo)\nfpp se refiere a casos de tuberculosis pulmonar que se pueden detectar mediante examen de frotis pulmonar (frotis pulmonar positivo)\n\n\nLa letra que aparece después del último _ se refiere al sexo de los pacientes. El conjunto de datos agrupa en hombres (h) y mujeres (m).\nLos números finales se refieren al grupo etareo que se ha organizado en siete categorías:\n\n\n014 = 0 - 14 años de edad\n1524 = 15 – 24 años de edad\n2534 = 25 – 34 años de edad\n3544 = 35 – 44 años de edad\n4554 = 45 – 54 años de edad\n5564 = 55 – 64 años de edad\n65 = 65 o más años de edad\n\nNecesitamos hacer un pequeño cambio al formato de los nombres de las columnas: desafortunadamente lo nombres de las columnas son ligeramente inconsistentes debido a que en lugar de nuevos_recaida tenemos nuevosrecaida (es difícil darse cuenta de esto en esta parte, pero si no lo arreglas habrá errores en los pasos siguientes). Para esto, la idea básica es bastante simple: reemplazar los caracteres “nuevosrecaida” por “nuevos_recaida”. Esto genera nombres de variables consistentes.\n\noms2 <- oms1 %>%\n  mutate(clave = stringr::str_replace(clave, \"nuevosrecaida\", \"nuevos_recaida\"))\noms2\n\n# A tibble: 76,046 × 6\n   pais       iso2  iso3   anio clave            casos\n   <chr>      <chr> <chr> <int> <chr>            <int>\n 1 Afganistán AF    AFG    1997 nuevos_fpp_h014      0\n 2 Afganistán AF    AFG    1997 nuevos_fpp_h1524    10\n 3 Afganistán AF    AFG    1997 nuevos_fpp_h2534     6\n 4 Afganistán AF    AFG    1997 nuevos_fpp_h3544     3\n 5 Afganistán AF    AFG    1997 nuevos_fpp_h4554     5\n 6 Afganistán AF    AFG    1997 nuevos_fpp_h5564     2\n 7 Afganistán AF    AFG    1997 nuevos_fpp_h65       0\n 8 Afganistán AF    AFG    1997 nuevos_fpp_m014      5\n 9 Afganistán AF    AFG    1997 nuevos_fpp_m1524    38\n10 Afganistán AF    AFG    1997 nuevos_fpp_m2534    36\n# … with 76,036 more rows\n\n\nUna vez reemplazado, nos facilita separar los valores en cada código aplicando separate() dos veces. La primera aplicación dividirá los códigos en cada _.\n\noms3 <- oms2 %>%\n  separate(clave, c(\"nuevos\", \"tipo\", \"sexo_edad\"), sep = \"_\")\noms3\n\n# A tibble: 76,046 × 8\n   pais       iso2  iso3   anio nuevos tipo  sexo_edad casos\n   <chr>      <chr> <chr> <int> <chr>  <chr> <chr>     <int>\n 1 Afganistán AF    AFG    1997 nuevos fpp   h014          0\n 2 Afganistán AF    AFG    1997 nuevos fpp   h1524        10\n 3 Afganistán AF    AFG    1997 nuevos fpp   h2534         6\n 4 Afganistán AF    AFG    1997 nuevos fpp   h3544         3\n 5 Afganistán AF    AFG    1997 nuevos fpp   h4554         5\n 6 Afganistán AF    AFG    1997 nuevos fpp   h5564         2\n 7 Afganistán AF    AFG    1997 nuevos fpp   h65           0\n 8 Afganistán AF    AFG    1997 nuevos fpp   m014          5\n 9 Afganistán AF    AFG    1997 nuevos fpp   m1524        38\n10 Afganistán AF    AFG    1997 nuevos fpp   m2534        36\n# … with 76,036 more rows\n\n\nA continuación podemos eliminar la columna nuevos, ya que es constante en este dataset. Además eliminaremos iso2 e iso3 ya que son redundantes.\n\noms3 %>%\n  count(nuevos)\n\n# A tibble: 1 × 2\n  nuevos     n\n  <chr>  <int>\n1 nuevos 76046\n\noms4 <- oms3 %>%\n  select(-nuevos, -iso2, -iso3)\n\nLuego separamos sexo_edad en sexo y edad dividiendo luego del primer carácter:\n\noms5 <- oms4 %>%\n  separate(sexo_edad, c(\"sexo\", \"edad\"), sep = 1)\noms5\n\n# A tibble: 76,046 × 6\n   pais        anio tipo  sexo  edad  casos\n   <chr>      <int> <chr> <chr> <chr> <int>\n 1 Afganistán  1997 fpp   h     014       0\n 2 Afganistán  1997 fpp   h     1524     10\n 3 Afganistán  1997 fpp   h     2534      6\n 4 Afganistán  1997 fpp   h     3544      3\n 5 Afganistán  1997 fpp   h     4554      5\n 6 Afganistán  1997 fpp   h     5564      2\n 7 Afganistán  1997 fpp   h     65        0\n 8 Afganistán  1997 fpp   m     014       5\n 9 Afganistán  1997 fpp   m     1524     38\n10 Afganistán  1997 fpp   m     2534     36\n# … with 76,036 more rows\n\n\n¡Ahora la base de datos oms está ordenado!"
  },
  {
    "objectID": "posts/tidyexam/index.html#resumen",
    "href": "posts/tidyexam/index.html#resumen",
    "title": "Ordenar datos con el paquete Tidyverse",
    "section": "Resumen",
    "text": "Resumen\nEn la anterior sección se hizo el procedimiento de ordenación paso a paso, asignando los resultados intermedios a nuevas variables. Esta no es la forma típica de trabajo. En realidad, los códigos debería ser de manera incremental usando pipes (\"%>%):\n\nfsdata<- oms %>%\n  pivot_longer(\n    cols = nuevos_fpp_h014:nuevosrecaida_m65,\n    names_to = \"clave\", \n    values_to = \"valor\", \n    values_drop_na = TRUE) %>%\n  mutate(clave = stringr::str_replace(clave, \"nuevosrecaida\", \"nuevos_recaida\")) %>%\n  separate(clave, c(\"nuevos\", \"tipo\", \"sexo_edad\")) %>%\n  select(-nuevos, -iso2, -iso3) %>%\n  separate(sexo_edad, c(\"sexo\", \"edad\"), sep = 1)\nfsdata\n\n# A tibble: 76,046 × 6\n   pais        anio tipo  sexo  edad  valor\n   <chr>      <int> <chr> <chr> <chr> <int>\n 1 Afganistán  1997 fpp   h     014       0\n 2 Afganistán  1997 fpp   h     1524     10\n 3 Afganistán  1997 fpp   h     2534      6\n 4 Afganistán  1997 fpp   h     3544      3\n 5 Afganistán  1997 fpp   h     4554      5\n 6 Afganistán  1997 fpp   h     5564      2\n 7 Afganistán  1997 fpp   h     65        0\n 8 Afganistán  1997 fpp   m     014       5\n 9 Afganistán  1997 fpp   m     1524     38\n10 Afganistán  1997 fpp   m     2534     36\n# … with 76,036 more rows"
  },
  {
    "objectID": "posts/tidyexam/index.html#conclusión",
    "href": "posts/tidyexam/index.html#conclusión",
    "title": "Ordenar datos con el paquete Tidyverse",
    "section": "Conclusión",
    "text": "Conclusión\nEs un ejemplo muy bueno para practicar y usar las diferentes funciones de tidyverse en la ordenación de datos."
  },
  {
    "objectID": "posts/anova/index.html",
    "href": "posts/anova/index.html",
    "title": "Análisis de Varianza y Prueba de Promedios en R",
    "section": "",
    "text": "El análisis de varianza es una prueba estadística para determinar si dos o más medias poblacionales son diferentes entre si. En otras palabras, se usa para comparar dos o más grupos para ver si son significativamente diferentes.\nEn el resto del post lo comentaremos desde un punto de vista más práctico y en particular abordaremos los siguientes puntos:\n\nel objetivo del análisis de varianza y cuándo debe usarse\ncómo realizar el ANVA en R\ncómo interpretar los resultados del ANVA\ncomprender la noción de prueba de promedios e interpretar los resultados\ncómo visualizar los resultados de ANVA y pruebas de promedio"
  },
  {
    "objectID": "posts/anova/index.html#datos",
    "href": "posts/anova/index.html#datos",
    "title": "Análisis de Varianza y Prueba de Promedios en R",
    "section": "Datos",
    "text": "Datos\nEl dato que se utilizará es iris, que se encuentra en la base de datos de R. Estos datos como tratamientos tienen tres especies (setosa, versicolor y virginica) y cuatro variables (Sepal.Length, Sepal.Width, Petal.Length y Petal.Width) cuantitativas\n\n#paquetes R a utilizar\nlibrary(tidyverse)\nlibrary(easyanova)\nlibrary(car)\nlibrary(lattice)\nlibrary(multcomp)\nlibrary(ggpubr)\nlibrary(rstatix)\n\nLa librería de easyanova es un paquete para realizar análisis de experimentos agrícolas y animales. Las funciones de esta librería son fáciles de usar. Realiza análisis en varios diseños, con datos balanceados y no balanceados.\nSalida de datos a utilizar:\n\n#datos\ntibble(iris)\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# … with 140 more rows\n\n\n\n#inspección de datos\np <- ggplot(iris) +\n  aes(x = Species, y = Sepal.Width, color = Species) +\n  geom_jitter() +\n  theme(legend.position = \"none\")\n\nlibrary(plotly)\nfig <- ggplotly(p)\n\nfig"
  },
  {
    "objectID": "posts/anova/index.html#objetivo-del-anva",
    "href": "posts/anova/index.html#objetivo-del-anva",
    "title": "Análisis de Varianza y Prueba de Promedios en R",
    "section": "Objetivo del ANVA",
    "text": "Objetivo del ANVA\nComo se mencionó en la introducción, el ANVA se usa para comparar grupos (en la práctica, 3 o más grupos). De manera más general, se utiliza para:\n\nestudiar si las mediciones son similares en diferentes modalidades (también llamadas niveles o tratamientos en el contexto de ANVA) de una variable categórica\ncomparar el impacto de los diferentes niveles de una variable categórica sobre una variable cuantitativa\nexplicar una variable cuantitativa basada en una variable cualitativa"
  },
  {
    "objectID": "posts/anova/index.html#supuestos-subyacentes-de-anva",
    "href": "posts/anova/index.html#supuestos-subyacentes-de-anva",
    "title": "Análisis de Varianza y Prueba de Promedios en R",
    "section": "Supuestos subyacentes de ANVA",
    "text": "Supuestos subyacentes de ANVA\nComo ocurre con muchas pruebas estadísticas, hay algunas suposiciones que deben cumplirse para poder interpretar los resultados. Cuando no se cumplen uno o varios supuestos, aunque técnicamente es posible realizar estas pruebas, sería incorrecto interpretar los resultados y confiar en las conclusiones.\n\n1. Tipo de variable\nLas variables dependientes Sepal.Length, Sepal.Width, Petal.Length y Petal.Width es una variable cuantitativa y la variable independiente Species es cualitativa (con 3 niveles correspondientes a las 3 especies). Así que tenemos una combinación de los dos tipos de variables y se cumple este supuesto.\n\n\n2. Independencia\nSe asume la independencia de las observaciones ya que los datos se han recopilado de una parte de la población seleccionada al azar y las mediciones dentro y entre las 3 muestras no están relacionadas.\nEl supuesto de independencia se verifica con mayor frecuencia con base en el diseño del experimento y en el buen control de las condiciones experimentales, como es el caso aquí. Sin embargo, si realmente desea probarlo de manera más formal, puede probarlo mediante una prueba estadística: la prueba de Durbin-Watson (en R: durbinWatsonTest(res_lm) donde res_lm es un modelo lineal). La hipótesis nula de esta prueba especifica un coeficiente de autocorrelación = 0, mientras que la hipótesis alternativa especifica un coeficiente de autocorrelación ≠ 0.\n\n\n3. Normalidad\nRecuerde que la normalidad de los residuos se puede probar visualmente mediante un histograma y un gráfico QQ, y/o formalmente mediante una prueba de normalidad (prueba de Shapiro-Wilk, por ejemplo).\nAntes de verificar el supuesto de normalidad, primero debemos calcular el ANVA. Luego guardamos los resultados en res_aov:\n\nres_aov <- aov(Sepal.Width ~ Species,\n  data = iris\n)\n\nAhora podemos comprobar la normalidad visualmente:\n\npar(mfrow = c(1, 2)) # combine plots\n\n# histogram\nhist(res_aov$residuals)\n\n# QQ-plot\nqqPlot(res_aov$residuals,\n  id = FALSE # id = FALSE to remove point identification\n)\n\n\n\n\nA partir del histograma y el gráfico QQ anteriores, ya podemos ver que el supuesto de normalidad parece cumplirse. De hecho, el histograma forma aproximadamente una curva de campana, lo que indica que los residuos siguen una distribución normal. Además, los puntos en las gráficas QQ siguen aproximadamente la línea recta y la mayoría de ellos están dentro de las bandas de confianza, lo que también indica que los residuos siguen aproximadamente una distribución normal.\nAlgunos investigadores se detienen aquí y asumen que se cumple la normalidad, mientras que otros también prueban la suposición a través de una prueba estadística formal. Es su elección probarlo (i) solo visualmente, (ii) solo a través de una prueba de normalidad, o (iii) tanto visualmente como a través de una prueba de normalidad. Sin embargo, tenga en cuenta los dos puntos siguientes:\n\n\nANVA es bastante robusto a pequeñas desviaciones de la normalidad. Esto significa que no es un problema (desde la perspectiva de la interpretación de los resultados de ANVA) si un pequeño número de puntos se desvía ligeramente de la normalidad,\nLas pruebas de normalidad son a veces bastante conservadoras, lo que significa que la hipótesis nula de normalidad puede rechazarse debido a una desviación limitada de la normalidad. Este es especialmente el caso con muestras grandes, ya que la potencia de la prueba aumenta con el tamaño de la muestra.\n\n\nEn la práctica, se tiende a preferir el (i) enfoque visual solamente, pero nuevamente, esto es una cuestión de elección personal y también depende del contexto del análisis. Tambien, puede utilizar la prueba de Shapiro-Wilk o la prueba de Kolmogorov-Smirnov, entre otras.\n\n\n4. Igualdad de varianzas - homogeneidad\nSuponiendo que los residuos siguen una distribución normal, ahora es el momento de comprobar si las varianzas son iguales entre especies o no. El resultado tendrá un impacto en si usamos el ANVA o la prueba de Welch.\nEsto se puede verificar nuevamente visualmente, a través de una gráfica de caja o gráfica de puntos, o más formalmente a través de una prueba estadística (la prueba de Levene, entre otras).\nVisualmente tenemos:\n\n# Boxplot\nboxplot(Sepal.Width ~ Species,\n  data = iris\n)\n\n\n\n\n\n# Dotplot\n\ndotplot(Sepal.Width ~ Species,\n  data = iris\n)\n\n\n\n\nTanto la gráfica de boxplot como la gráfica de puntos muestran una variación similar para las diferentes especies. En el boxplot, esto se puede ver por el hecho de que las cajas y los bigotes tienen un tamaño comparable para todas las especies. Hay un par de valores atípicos como lo muestran los puntos fuera de los bigotes, pero esto no cambia el hecho de que la dispersión es más o menos la misma entre las diferentes especies.\nEn la gráfica de puntos, esto se puede ver por el hecho de que los puntos para las 3 especies tienen más o menos el mismo rango, un signo de la dispersión y, por lo tanto, la varianza es similar.\nAl igual que el supuesto de normalidad, si cree que el enfoque visual no es suficiente, puede probar formalmente la igualdad de las varianzas con una prueba de Levene o de Bartlett. Observe que la prueba de Levene es menos sensible a las desviaciones de la distribución normal que la prueba de Bartlett.\nLas hipótesis nula y alternativa para ambas pruebas son:\n\nH0: las variaciones son iguales\nH1: al menos una varianza es diferente\n\nEn R, la prueba de Levene se puede realizar gracias a la función leveneTest() del paquete {car}:\n\n# Levene's test\n\nleveneTest(Sepal.Width ~ Species,\n  data = iris\n)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(>F)\ngroup   2  0.5902 0.5555\n      147               \n\n\nSiendo el p-valor mayor que el nivel de significancia de 0.05, no rechazamos la hipótesis nula, por lo que no podemos rechazar la hipótesis de que las varianzas son iguales entre especies (p-valor = 0.556).\nEste resultado también está en línea con el enfoque visual, por lo que la homogeneidad de las variaciones se cumple tanto visual como formalmente."
  },
  {
    "objectID": "posts/anova/index.html#análisis-de-varianza-en-r",
    "href": "posts/anova/index.html#análisis-de-varianza-en-r",
    "title": "Análisis de Varianza y Prueba de Promedios en R",
    "section": "Análisis de varianza en R",
    "text": "Análisis de varianza en R\nEl ANVA puede ayudarnos a hacer inferencias sobre la población dada la muestra en cuestión y ayudarnos a responder la pregunta de investigación “¿Existe diferencia en ancho de sépalo para las 3 especies?”.\nEl ANVA en R se puede realizar de varias formas, de las cuales tres se presentan a continuación:\na). Con la función oneway.test():\n\n# primer metodo:\noneway.test(Sepal.Width ~ Species,\n  data = iris,\n  var.equal = TRUE # asumiendo varianzas iguales\n)\n\n\n    One-way analysis of means\n\ndata:  Sepal.Width and Species\nF = 49.16, num df = 2, denom df = 147, p-value < 2.2e-16\n\n\nb). Con las funciones de summary() y aov():\n\n# 2nd method:\nres_aov <- aov(Sepal.Width ~ Species,\n  data = iris\n)\n\nsummary(res_aov)\n\n             Df Sum Sq Mean Sq F value Pr(>F)    \nSpecies       2  11.35   5.672   49.16 <2e-16 ***\nResiduals   147  16.96   0.115                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nComo puede ver en los dos resultados anteriores, la estadística de prueba (F = en el primer método y el valor F en el segundo) y el p-valor (p-valor en el primer método y Pr (> F) en el segundo) son exactamente iguales para ambos métodos, lo que significa que en caso de variaciones iguales, los resultados y las conclusiones no cambiarán.\nLa ventaja del primer método es que es fácil cambiar del ANVA (utilizado cuando las variaciones son iguales) a la prueba de Welch (utilizado cuando las variaciones son desiguales). Esto se puede hacer reemplazando nvar.equal = TRUE por var.equal = FALSE, como se presenta a continuación:\n\noneway.test(Sepal.Width ~ Species,\n  data = iris,\n  var.equal = FALSE # asumiendo variaciones desiguales\n)\n\n\n    One-way analysis of means (not assuming equal variances)\n\ndata:  Sepal.Width and Species\nF = 45.012, num df = 2.000, denom df = 97.402, p-value = 1.433e-14\n\n\nSin embargo, la ventaja del segundo método es que:\n\nSe imprime la tabla ANVA completa (con grados de libertad, cuadrados medios, etc.), lo que puede ser de interés en algunos casos (teóricos).\nlos resultados del ANVA (res_aov) se pueden guardar para su uso posterior (especialmente útil para pruebas de promedio)\n\n\nInterpretaciones de los resultados del ANVA\nDado que el p-valor es menor que 0.05, rechazamos la hipótesis nula, por lo que rechazamos la hipótesis de que todas las medias son iguales. Por tanto, podemos concluir que al menos una especie es diferente a las otras en términos del ancho de sépalo (p-valor <2.2e-16).\n\n\n¿Que sigue?\nSi no se rechaza la hipótesis nula (p-valor ≥ 0,05), significa que no rechazamos la hipótesis de que todos los grupos son iguales. El ANVA más o menos se detiene aquí. Por supuesto, se pueden realizar otros tipos de análisis, pero, dados los datos disponibles, no pudimos probar que al menos un grupo fuera diferente, por lo que generalmente no avanzamos más con el ANVA.\nPor el contrario, si y solo si se rechaza la hipótesis nula (como es nuestro caso ya que el p-valor < 0.05), probamos que al menos un grupo es diferente. Podemos decidir detenernos aquí si solo estamos interesados en probar si todas las especies son iguales en términos de ancho de sépalo.\nPero la mayoría de las veces, cuando demostramos gracias a un ANVA que al menos un grupo es diferente, también nos interesa saber cuál es diferente. Para probar esto, necesitamos usar otros tipos de prueba, denominados pruebas de promedio o pruebas de comparación múltiple por pares. Esta familia de pruebas estadísticas es el tema de las siguientes secciones."
  },
  {
    "objectID": "posts/anova/index.html#pruebas-de-promedio-en-r-y-su-interpretación",
    "href": "posts/anova/index.html#pruebas-de-promedio-en-r-y-su-interpretación",
    "title": "Análisis de Varianza y Prueba de Promedios en R",
    "section": "Pruebas de promedio en R y su interpretación",
    "text": "Pruebas de promedio en R y su interpretación\nLas pruebas de promedio son una familia de pruebas estadísticas, por lo que hay varias. Las más utilizadas son las pruebas Tukey HSD y Dunnett:\n\nTukey HSD se utiliza para comparar todos los grupos entre sí (por lo que todas las posibles comparaciones de 2 grupos).\nDunnett se utiliza para hacer comparaciones con un grupo de referencia. Por ejemplo, considere 2 grupos de tratamiento y un grupo de control. Si solo desea comparar los 2 grupos de tratamiento con respecto al grupo de control y no desea comparar los 2 grupos de tratamiento entre sí, se prefiere la prueba de Dunnett.\n\nAmbas pruebas se presentan en las siguientes secciones.\n\nPrueba de Tukey HSD\nEn nuestro caso, dado que no existe una especie de “referencia” y nos interesa comparar todas las especies, vamos a utilizar la prueba de Tukey HSD.\nEn R, la prueba de Tukey HSD se realiza de la siguiente manera. Aquí es donde el segundo método para realizar el ANVA resulta útil porque los resultados (res_aov) se reutilizan para la prueba de promedios:\n\n# Prueba de Tukey HSD:\npost_test <- glht(res_aov,\n  linfct = mcp(Species = \"Tukey\")\n)\nsummary(post_test)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: aov(formula = Sepal.Width ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(>|t|)    \nversicolor - setosa == 0    -0.65800    0.06794  -9.685  < 1e-04 ***\nvirginica - setosa == 0     -0.45400    0.06794  -6.683  < 1e-04 ***\nvirginica - versicolor == 0  0.20400    0.06794   3.003  0.00871 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nEn el resultado de la prueba Tukey HSD, nos interesa la tabla que se muestra después de las Hipótesis lineales: más precisamente, en la primera y última columna de la tabla. La primera columna muestra las comparaciones que se han realizado; la última columna (Pr(>|t|)) muestra los p-valores ajustados para cada comparación (con la hipótesis nula siendo los dos grupos iguales y la hipótesis alternativa siendo los dos grupos diferentes).\nSon estos p-valores ajustados los que se utilizan para probar si dos grupos son significativamente diferentes o no. En nuestro ejemplo, probamos:\n\nversicolor vs setosa (línea versicolor - setosa == 0)\nvirginica vs setosa (línea virginica - setosa == 0)\nvirginica vs versicolor (línea virginica - versicolor == 0)\n\nLos tres p-valores son menores que 0.05, por lo que rechazamos la hipótesis nula para todas las comparaciones, lo que significa que todas las especies son significativamente diferentes en términos de ancho de sépalo.\nTenga en cuenta que la prueba Tukey HSD también se puede realizar en R con la función TukeyHSD():\n\nTukeyHSD(res_aov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Sepal.Width ~ Species, data = iris)\n\n$Species\n                       diff         lwr        upr     p adj\nversicolor-setosa    -0.658 -0.81885528 -0.4971447 0.0000000\nvirginica-setosa     -0.454 -0.61485528 -0.2931447 0.0000000\nvirginica-versicolor  0.204  0.04314472  0.3648553 0.0087802\n\n\nCon este código, es la columna p adj (también la última columna) la que interesa. Tenga en cuenta que las conclusiones son las mismas que las anteriores: todas las especies son significativamente diferentes en términos de ancho de sépalo."
  },
  {
    "objectID": "posts/anova/index.html#visualización-de-anva-y-pruebas-de-promedio",
    "href": "posts/anova/index.html#visualización-de-anva-y-pruebas-de-promedio",
    "title": "Análisis de Varianza y Prueba de Promedios en R",
    "section": "Visualización de ANVA y pruebas de promedio",
    "text": "Visualización de ANVA y pruebas de promedio\nPara realizar de forma más fácil un análisis de varianza, se puede usar la librería easyanova para analizar diferentes diseños experimentales.\n\nAnálisis de varianza con easyanova\nPara proceder con ANVA los datos de iris se selecciona y ordena para dar uso con el paquete easyanova.\n\nfsdata <- iris %>%\n  dplyr::select(Species, Sepal.Width)\ntibble(fsdata)\n\n# A tibble: 150 × 2\n   Species Sepal.Width\n   <fct>         <dbl>\n 1 setosa          3.5\n 2 setosa          3  \n 3 setosa          3.2\n 4 setosa          3.1\n 5 setosa          3.6\n 6 setosa          3.9\n 7 setosa          3.4\n 8 setosa          3.4\n 9 setosa          2.9\n10 setosa          3.1\n# … with 140 more rows\n\n\n\n# Análisis de varianza para DCA\n\nr1 <- ea1(data = fsdata, # Base de datos\n          design = 1, # Diseño experimental: 1=DCA, 2=DBCA, etc.\n          alpha = 0.05) # Probabilidad estadística\n\n\n\nr1\n\n$`Analysis of variance`\n            df type I SS mean square F value    p>F\ntreatments   2   11.3449      5.6725   49.16 <0.001\nResiduals  147   16.9620      0.1154       -      -\n\n$Means\n   treatment  mean standard.error tukey snk duncan t scott_knott\n1     setosa 3.428          0.048     a   a      a a           a\n2  virginica 2.974          0.048     b   b      b b           b\n3 versicolor 2.770          0.048     c   c      c c           c\n\n$`Multiple comparison test`\n                    pair contrast p(tukey) p(snk) p(duncan)   p(t)\n1     setosa - virginica    0.454   0.0000 0.0000    0.0000 0.0000\n2    setosa - versicolor    0.658   0.0000 0.0000    0.0000 0.0000\n3 virginica - versicolor    0.204   0.0087 0.0031    0.0031 0.0031\n\n$`Residual analysis`\n$`Residual analysis`$`residual analysis`\n                               values\np.value Shapiro-Wilk test      0.3230\np.value Bartlett test          0.3515\ncoefficient of variation (%)  11.1100\nfirst value most discrepant   42.0000\nsecond value most discrepant  16.0000\nthird value most discrepant  118.0000\n\n$`Residual analysis`$residuals\n     1      2      3      4      5      6      7      8      9     10     11 \n 0.072 -0.428 -0.228 -0.328  0.172  0.472 -0.028 -0.028 -0.528 -0.328  0.272 \n    12     13     14     15     16     17     18     19     20     21     22 \n-0.028 -0.428 -0.428  0.572  0.972  0.472  0.072  0.372  0.372 -0.028  0.272 \n    23     24     25     26     27     28     29     30     31     32     33 \n 0.172 -0.128 -0.028 -0.428 -0.028  0.072 -0.028 -0.228 -0.328 -0.028  0.672 \n    34     35     36     37     38     39     40     41     42     43     44 \n 0.772 -0.328 -0.228  0.072  0.172 -0.428 -0.028  0.072 -1.128 -0.228  0.072 \n    45     46     47     48     49     50     51     52     53     54     55 \n 0.372 -0.428  0.372 -0.228  0.272 -0.128  0.430  0.430  0.330 -0.470  0.030 \n    56     57     58     59     60     61     62     63     64     65     66 \n 0.030  0.530 -0.370  0.130 -0.070 -0.770  0.230 -0.570  0.130  0.130  0.330 \n    67     68     69     70     71     72     73     74     75     76     77 \n 0.230 -0.070 -0.570 -0.270  0.430  0.030 -0.270  0.030  0.130  0.230  0.030 \n    78     79     80     81     82     83     84     85     86     87     88 \n 0.230  0.130 -0.170 -0.370 -0.370 -0.070 -0.070  0.230  0.630  0.330 -0.470 \n    89     90     91     92     93     94     95     96     97     98     99 \n 0.230 -0.270 -0.170  0.230 -0.170 -0.470 -0.070  0.230  0.130  0.130 -0.270 \n   100    101    102    103    104    105    106    107    108    109    110 \n 0.030  0.326 -0.274  0.026 -0.074  0.026  0.026 -0.474 -0.074 -0.474  0.626 \n   111    112    113    114    115    116    117    118    119    120    121 \n 0.226 -0.274  0.026 -0.474 -0.174  0.226  0.026  0.826 -0.374 -0.774  0.226 \n   122    123    124    125    126    127    128    129    130    131    132 \n-0.174 -0.174 -0.274  0.326  0.226 -0.174  0.026 -0.174  0.026 -0.174  0.826 \n   133    134    135    136    137    138    139    140    141    142    143 \n-0.174 -0.174 -0.374  0.026  0.426  0.126  0.026  0.126  0.126  0.126 -0.274 \n   144    145    146    147    148    149    150 \n 0.226  0.326  0.026 -0.474  0.026  0.426  0.026 \n\n$`Residual analysis`$`standardized residuals`\n          1           2           3           4           5           6 \n 0.21339641 -1.26852308 -0.67575529 -0.97213918  0.50978030  1.39893200 \n          7           8           9          10          11          12 \n-0.08298749 -0.08298749 -1.56490698 -0.97213918  0.80616420 -0.08298749 \n         13          14          15          16          17          18 \n-1.26852308 -1.26852308  1.69531589  2.88085148  1.39893200  0.21339641 \n         19          20          21          22          23          24 \n 1.10254810  1.10254810 -0.08298749  0.80616420  0.50978030 -0.37937139 \n         25          26          27          28          29          30 \n-0.08298749 -1.26852308 -0.08298749  0.21339641 -0.08298749 -0.67575529 \n         31          32          33          34          35          36 \n-0.97213918 -0.08298749  1.99169979  2.28808369 -0.97213918 -0.67575529 \n         37          38          39          40          41          42 \n 0.21339641  0.50978030 -1.26852308 -0.08298749  0.21339641 -3.34321036 \n         43          44          45          46          47          48 \n-0.67575529  0.21339641  1.10254810 -1.26852308  1.10254810 -0.67575529 \n         49          50          51          52          53          54 \n 0.80616420 -0.37937139  1.27445076  1.27445076  0.97806686 -1.39300432 \n         55          56          57          58          59          60 \n 0.08891517  0.08891517  1.57083466 -1.09662042  0.38529907 -0.20746873 \n         61          62          63          64          65          66 \n-2.28215601  0.68168296 -1.68938822  0.38529907  0.38529907  0.97806686 \n         67          68          69          70          71          72 \n 0.68168296 -0.20746873 -1.68938822 -0.80023652  1.27445076  0.08891517 \n         73          74          75          76          77          78 \n-0.80023652  0.08891517  0.38529907  0.68168296  0.08891517  0.68168296 \n         79          80          81          82          83          84 \n 0.38529907 -0.50385263 -1.09662042 -1.09662042 -0.20746873 -0.20746873 \n         85          86          87          88          89          90 \n 0.68168296  1.86721855  0.97806686 -1.39300432  0.68168296 -0.80023652 \n         91          92          93          94          95          96 \n-0.50385263  0.68168296 -0.50385263 -1.39300432 -0.20746873  0.68168296 \n         97          98          99         100         101         102 \n 0.38529907  0.38529907 -0.80023652  0.08891517  0.96621151 -0.81209188 \n        103         104         105         106         107         108 \n 0.07705981 -0.21932408  0.07705981  0.07705981 -1.40485967 -0.21932408 \n        109         110         111         112         113         114 \n-1.40485967  1.85536320  0.66982761 -0.81209188  0.07705981 -1.40485967 \n        115         116         117         118         119         120 \n-0.51570798  0.66982761  0.07705981  2.44813099 -1.10847578 -2.29401137 \n        121         122         123         124         125         126 \n 0.66982761 -0.51570798 -0.51570798 -0.81209188  0.96621151  0.66982761 \n        127         128         129         130         131         132 \n-0.51570798  0.07705981 -0.51570798  0.07705981 -0.51570798  2.44813099 \n        133         134         135         136         137         138 \n-0.51570798 -0.51570798 -1.10847578  0.07705981  1.26259540  0.37344371 \n        139         140         141         142         143         144 \n 0.07705981  0.37344371  0.37344371  0.37344371 -0.81209188  0.66982761 \n        145         146         147         148         149         150 \n 0.96621151  0.07705981 -1.40485967  0.07705981  1.26259540  0.07705981 \n\n\nEn la salida se puede observar el resultado de análisis de varianza, prueba de promedios y comparación múltiple de medias. Estas salidas son muy fáciles de obtener y poder interpretar las mismas. Asimismo, se puede verificar la normalidad y coeficiente de variación de los datos.\n\n\nVisualización de la prueba de promedios\nSi está interesado en incluir resultados de ANVA y pruebas de promedio directamente en los boxplot, aquí hay un fragmento de código que puede ser de su interés:\n\n#paquete para p-valor en la visualización de prueba de promedios\n\ndat <- iris\n# Editar desde aquí\nx <- which(names(dat) == \"Species\") #variable de agrupación\ny <- which(names(dat) == \"Sepal.Width\") \n#variables para la prueba de promedios\n          #| names(dat) == \"Sepal.Length\"\n          #| names(dat) == \"Petal.Length\"\n          #| names(dat) == \"Petal.Width\")\nmethod1 <- \"anova\" # Una de \"anova\" o \"kruskal.test\"\nmethod2 <- \"t.test\" # Una de \"wilcox.test\" o \"t.test\"\nmy_comparisons <- list(c(\"setosa\", \"versicolor\"), \n                       c(\"setosa\", \"virginica\"), \n                       c(\"versicolor\", \"virginica\")) \n# comparaciones para pruebas de promedio\n# Editar hasta aquí\n\n# Edit at your own risk\nfor (i in y) {\n  for (j in x) {\n    p <- ggboxplot(dat,\n      x = colnames(dat[j]), y = colnames(dat[i]),\n      color = colnames(dat[j]),\n      legend = \"none\",\n      palette = \"npg\",\n      add = \"jitter\"\n    )\n    print(\n      p + stat_compare_means(aes(\n        label = paste0(..method.., \", p-value = \", ..p.format..)),\n        method = method1, label.y = max(dat[, i], na.rm = TRUE)\n      )\n      + stat_compare_means(comparisons = my_comparisons, \n                           method = method2, label = \"p.format\") \n      # remove if p-value of ANOVA or Kruskal-Wallis test >= alpha\n    )\n  }\n}\n\n\n\n\nOtra opción de gráfica para observar la significancia entre las medias de cada par de especies.\n\n# pairwise comparisons\n\npwc <- fsdata %>%\n  pairwise_t_test(\n    Sepal.Width ~ Species, pool.sd = FALSE,\n    p.adjust.method = \"none\"\n    )\n\n# Visualization: box plots with p-values\npwc <- pwc %>% add_xy_position(x = \"Species\")\nggboxplot(fsdata, x = \"Species\", y = \"Sepal.Width\",\n          color = \"Species\", \n          legend = \"none\", \n          add = \"jitter\") +\n  stat_pvalue_manual(pwc, hide.ns = TRUE)"
  },
  {
    "objectID": "posts/anova/index.html#conclusión",
    "href": "posts/anova/index.html#conclusión",
    "title": "Análisis de Varianza y Prueba de Promedios en R",
    "section": "Conclusión",
    "text": "Conclusión\nLa figura de prueba de promedios es muy buena opción para incluir en la sección de resultados de los reportes de investigación. La figura incluye el resultado de p-valor del análisis de varianza, además, p-valor para la comparación de medias entre especies o tratamientos de la investigación."
  },
  {
    "objectID": "posts/anova/index.html#referencias",
    "href": "posts/anova/index.html#referencias",
    "title": "Análisis de Varianza y Prueba de Promedios en R",
    "section": "Referencias",
    "text": "Referencias\n\nR bloggers 2020. ANOVA in R\nSoetewey A. 2020. How to do a t-test or ANOVA for more than one variable at once in R"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Franklin Santos",
    "section": "",
    "text": "Franklin Santos is plant and data scientist. He develops research work and data analysis. His research interests include plant and animal breeding. He directs a group of researchers and he is a undergraduate thesis advisor for the Agronomic Engineering Career at the Public University of El Alto."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Franklin Santos",
    "section": "Education",
    "text": "Education\n\nStatistics with R | 2020\n\nDuke University | Coursera Specialization\n\nAnimal Breeding and Genetics | 2020\n\nWageningen University & Research | edX Professional Certificate\n\nData Science | 2020\n\nJohns Hopkins University | Coursera Specialization\n\nAgronomist Engineer, B.Sc. | 2017\n\nEl Alto Public University"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Franklin Santos",
    "section": "Experience",
    "text": "Experience\n\nINIAF | Research Technician | January 2018 - June 2020\nGAM-Licoma | Director of Agricultural Development | June 2016 - Dec 2017\nINE | Municipal Census Chief | August 2013 - November 2013"
  },
  {
    "objectID": "about.html#interests",
    "href": "about.html#interests",
    "title": "Franklin Santos",
    "section": "Interests",
    "text": "Interests\n\nPlant and Animal Breeding\nMentoring\nData Science\nR programming"
  },
  {
    "objectID": "Blog.html",
    "href": "Blog.html",
    "title": "Posts",
    "section": "",
    "text": "El análisis de componentes principales nos permite resumir y visualizar la información de un conjunto de datos que contiene observaciones descritos por múltiples variables cuantitativas inter-correlacionadas.\n\n\n\n\n\n\nDec 15, 2020\n\n\nFranklin Santos\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nLa figura de prueba de promedios de TukeyHSD es una buena opción, ya que incluye p-valor del ANVA y de la comparación de medias entre tratamientos.\n\n\n\n\n\n\nNov 15, 2020\n\n\nFranklin Santos\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nAnálisis para variables categóricas utilizando la metodología de tablas cruzadas con la prueba de chi-cuadrado. Este análisis es una recopilación del libro Multivariate Analysis II: Practical Guide To Principal Component Methods in R.\n\n\n\n\n\n\nNov 7, 2020\n\n\nFranklin Santos\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n\n\n\n\nEs un ejemplo de caso extraido del libro R4DS.\n\n\n\n\n\n\nOct 31, 2020\n\n\nFranklin Santos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  }
]